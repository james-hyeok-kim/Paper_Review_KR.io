# 1.58-bit FLUX

저자 : Chenglin Yang1, Celong Liu1, Xueqing Deng1, Dongwon Kim2,Xing Mei1, Xiaohui Shen1, Liang-Chieh Chen1

1ByteDance 2POSTECH

발표 : 2024년 12월 24일 arXiv

논문 : [PDF](https://arxiv.org/pdf/2412.18653)

---

## 0. Summary

### PTQ

| 레이어 구분 | 가중치 비트 폭 (Weight) | 활성화 비트 폭 (Activation) | 비고 |
| :--- | :--- | :--- | :--- |
| 일반 선형 레이어<br>(Flux TransformerBlock 및<br>FluxSingle TransformerBlock 내 모든 선형 레이어) | 1.58-bit (Ternary)<br>$\{-1, 0, +1\}$ | 양자화 미적용 (제한 사항) | 모델 전체 파라미터의 99.5%(11.9B)에 해당하며, 이미지 데이터 없이 자기지도 학습으로 양자화 수행. |
| 임베딩 및 기타 레이어 | 양자화 미적용 | 양자화 미적용 | 전체 파라미터의 나머지 0.5%에 해당함. |

---

## 1. Introduction

### 주요 특징 및 방법론

* 포스트 트레이닝 양자화 (PTQ): 처음부터 모델을 다시 학습시켜야 하는 기존의 BitNet 방식과 달리, 이미 학습된 모델을 사후에 양자화하는 효율적인 방식을 택했습니다.
* 데이터 프리(Data-free): 양자화 과정에서 별도의 이미지 데이터에 접근할 필요 없이, FLUX.1-dev 모델 자체의 자기 지도 학습(Self-supervision)에만 의존합니다.

* 대상 범위: FLUX 비전 트랜스포머 매개변수의 99.5%(약 119억 개)를 1.58비트로 압축했습니다.

### 기술적 성과

<p align = 'center'>
<img width="883" height="390" alt="image" src="https://github.com/user-attachments/assets/833bb79c-7990-471c-889c-2aacf805c664" />
</p>

* 효율성 극대화: 모델 저장 공간을 7.7배 줄였으며, 추론 메모리 사용량을 5.1배 이상 절감했습니다.
* 성능 유지: 극심한 압축에도 불구하고 GenEval 및 T2I Compbench와 같은 벤치마크에서 기존의 풀 정밀도(Full-precision) 모델과 대등한 생성 품질을 유지함을 입증했습니다.
* 커스텀 커널 개발: 저비트 연산에 최적화된 전용 커널을 개발하여 추론 속도와 효율성을 더욱 향상시켰습니다.

---

## 2. Related Work

### 이미지 생성 모델의 양자화

* 확산 모델(Diffusion Models): 이미지 생성 모델을 위해 아다마르 변환(Hadamard transformations), 벡터 양자화, 부동 소수점 양자화, 혼합 비트 폭 할당 등 다양한 기법이 탐구되었습니다.
* 효율 최적화: 이러한 접근 방식들은 모델의 성능을 유지하면서도 계산 효율성을 최적화하는 것을 목표로 합니다.

### 1.58-bit FLUX의 차별점

* 최초의 FLUX 양자화: 최첨단 오픈 소스 텍스트-이미지(T2I) 모델인 FLUX를 대상으로 한 포스트 트레이닝(PTQ) 1.58비트 양자화에 집중했습니다.
* 이미지 데이터 불필요: 튜닝을 위한 별도의 이미지 데이터 없이도 효율적인 양자화를 달성했습니다.
* 최적화된 추론: 양자화 기법뿐만 아니라 이를 뒷받침하는 최적화된 추론 기술을 함께 제공하여 실질적인 속도와 메모리 이득을 챙겼습니다.

---

## 3. Experimental Results


### 3.1 Settings

#### 양자화 설정 (Quantization)

* 보정 데이터셋 (Calibration Dataset): 별도의 이미지 데이터 없이, Parti-1k 데이터셋과 T2I CompBench의 훈련 데이터에서 추출한 총 7,232개의 프롬프트만을 사용하여 보정 과정을 진행했습니다.
* 양자화 범위: FLUX 모델 내의 FluxTransformerBlock 및 FluxSingleTransformerBlock에 포함된 모든 선형 계층(Linear layers)의 가중치를 1.58비트로 양자화했습니다.
* 파라미터 비중: 이 양자화 과정은 비전 트랜스포머 전체 매개변수의 99.5%를 커버합니다.

#### 평가 설정 (Evaluation)
* 벤치마크 데이터셋: 모델의 성능 측정을 위해 GenEval 데이터셋과 T2I CompBench의 검증 데이터(validation split)를 활용했습니다.
* 생성 조건
    * GenEval: 553개의 프롬프트를 사용하며, 각 프롬프트당 4장의 이미지를 생성합니다.
    * T2I CompBench: 8개 카테고리(각 300개 프롬프트)에 대해 프롬프트당 10장의 이미지를 생성하여, 총 24,000장의 이미지를 평가에 사용했습니다.
* 해상도: 모든 평가 이미지는 기존 FLUX와 동일하게 $1024\times1024$ 해상도로 생성되었습니다.
* 비교 방식: 일관된 비교를 위해 모든 이미지 생성 시 동일한 잠재 노이즈(latent noise) 입력을 사용했습니다.

### 3.2. Results

#### 1. 생성 성능 (Performance)

<p align = 'center'>
<img width="900" height="489" alt="image" src="https://github.com/user-attachments/assets/bc76d473-223c-424e-b47c-6b48e95a420a" />
</p>

* 대등한 품질: T2I CompBench와 GenEval 벤치마크 평가 결과, 1.58-bit FLUX는 원본 FLUX와 비교했을 때 성능 차이가 거의 없음을 확인했습니다.
* 커널 적용 영향: 자체 개발한 선형 커널을 적용하기 전후의 성능 차이가 미미하여, 최적화된 구현의 정확성을 입증했습니다.
* 시각적 비교: 같은 노이즈 입력을 사용했을 때, 1.58-bit FLUX는 원본과 매우 유사하고 생생하며 실제적인 이미지를 생성했습니다.

#### 2. 하드웨어 효율성 (Efficiency)

<p align = 'center'>
<img width="439" height="240" alt="image" src="https://github.com/user-attachments/assets/e9a25b85-25d1-4900-8e5a-fa620892bc4b" />
</p>

* 저장 공간 절감: 모델 체크포인트 용량을 기존 대비 7.7배 줄였습니다.
* 메모리 최적화: 다양한 GPU 환경에서 추론 메모리 사용량을 5.1배 이상 감소시켰습니다.
* 저사양 GPU에서의 성능: 특히 L20이나 A10과 같이 성능이 낮거나 배포에 유리한 GPU에서 실행할 때 더 큰 지연 시간(Latency) 개선 효과를 보였습니다.

---

## 4. Conclusion and Discussion

### 핵심 성과 요약

* 획기적인 효율성: 커스텀 연산 커널을 통해 모델 저장 공간을 7.7배 줄였고, 추론 메모리 사용량을 5.1배 이상 절감했습니다.
* 품질 유지: 이러한 높은 압축률에도 불구하고 주요 T2I 벤치마크에서 기존 풀 정밀도 모델과 대등한 성능 및 높은 시각적 품질을 유지했습니다.
* 모바일 배포 가능성: 이번 연구가 모바일 기기용 고성능 모델 개발에 영감을 주기를 기대하고 있습니다.

### 현재의 한계점 및 향후 과제

* 속도 개선의 한계
    * 모델 크기와 메모리 사용량은 줄었지만, 아직 활성값 양자화(Activation Quantization)가 적용되지 않았습니다.
    * 또한 커널 구현이 완전히 최적화되지 않아 지연 시간(Latency)이 드라마틱하게 개선되지는 않았으며, 커뮤니티의 추가적인 최적화 노력을 기대하고 있습니다.

* 세부 시각적 품질
    * 1.58-bit FLUX는 텍스트 프롬프트에 정렬된 생생한 이미지를 생성하지만, 매우 높은 해상도에서 미세한 디테일(Fine details)을 렌더링하는 능력은 여전히 원본 FLUX에 비해 다소 뒤처집니다.


---


