# Generative Modeling via Drifting

저자: Mingyang Deng 1 He Li 1 Tianhong Li 1 Yilun Du 2 Kaiming He 1

1 MIT 2 Harvard University.

발표: 2026년 2월 4일 (arXiv:2602.04770)

논문: [PDF](https://arxiv.org/pdf/2602.04770)

---

<p align = 'center'>
<img width="717" height="285" alt="image" src="https://github.com/user-attachments/assets/58021a55-4c01-49ab-9e3f-6bcb15880ec4" />
</p>

* Drifting Models는 생성 모델링(Generative Modeling)을 위한 새로운 패러다임
* 기존의 확산(Diffusion) 또는 플로우 매칭(Flow Matching) 모델들이 추론 시에 여러 번의 반복적인 단계를 거쳐 노이즈를 데이터로 변환하는 것
* Drifting 모델은 학습 시간 동안의 반복적인 최적화 과정을 분포의 진화로 활용하여 추론 시에는 단 한 번의 단계(one-step inference)만으로 고품질의 데이터를 생성합니다.

---
## 1. Introduction

### 1. 핵심 개념: 학습 시간 동안의 분포 진화

* 푸시포워드(Pushforward) 모델링
    * 사전 분포 $p_{prior}$를 데이터 분포 $p_{data}$로 매핑하는 함수 $f$를 학습하는 과정으로 정의
    * 학습 과정의 활용: 딥러닝 최적화(예: SGD)는 본질적으로 반복
    * Drifting 모델은 이 학습 과정을 통해 푸시포워드 분포 $q = f_{\sharp} p_{prior}$ 가 점진적으로 데이터 분포에 맞춰지도록 합니다.
    * 드리프팅 필드(Drifting Field): 샘플의 이동을 제어하는 '드리프팅 필드'를 도입합니다. 이 필드는 생성된 분포 $q$와 실제 데이터 분포 $p$ 사이의 상호작용에 기반하며, 두 분포가 일치할 때 0이 되어 평형 상태에 도달합니다.
 

### 2. 주요 장점 및 성능

* 효율적인 추론: 별도의 반복적인 추론 절차가 필요 없는 단일 패스(single-pass) 네트워크로 구성되어 있어 효율적입니다.
* 상태 최첨단(SOTA) 결과: ImageNet $256\times256$ 데이터셋에서 단일 단계 생성 모델 중 가장 뛰어난 성능을 보였습니다.
    * 잠재 공간(Latent Space): FID 1.54 달성.
    * 픽셀 공간(Pixel Space): FID 1.61 달성.
* 모드 붕괴(Mode Collapse) 방지: 실제 데이터 분포의 여러 모드가 샘플을 끌어당기기 때문에 특정 모드로 뭉치는 현상에 강한 내성을 가집니다.

### 3. 학습 메커니즘

* 손실 함수: 드리프팅 필드의 제곱 노름(squared norm)을 최소화하는 간단한 학습 목표를 사용합니다.
* 특징 공간 활용: 고차원 데이터 생성을 위해 원본 데이터 공간 대신 사전 학습된 자기 자기주도 학습(SSL) 모델의 특징 공간(Feature Space)에서 드리프팅 손실을 계산하여 풍부한 그래디언트 정보를 얻습니다.

$$\|v(x, t)\|^2 = \sum_{i=1}^{d} |v_i(x, t)|^2$$

* $v(x, t)$가 주어졌을 때, 특정 위치 $x$에서의 제곱 노름은 해당 벡터의 길이를 제곱한 값입니다. 유클리드 공간에서는 보통 $L^2$ 노름을 사용
* 오직 크기의 제곱만을 나타낸다

---

## 2. Related Works

### 1. 관련 연구 섹션의 목적

* 지식의 지도 작성: 현재 분야가 어디까지 발전했는지 보여줍니다.
* 차별성 강조: 기존 연구들의 한계점(예: 계산 복잡도, 경로의 불안정성 등)을 지적하며 내 연구의 필요성을 부각합니다.
* 정당성 부여: 내가 사용하는 방법론(제곱 노름 규제 등)이 이전의 어떤 이론적 토대 위에 있는지 설명합니다.

### 2. '드리프팅 필드' 관련 논문의 전형적인 구조

1) 생성 모델의 발전 (Diffusion & Flow Matching)
    1) Score-based Models & DDPM: 노이즈를 제거하며 데이터를 생성하는 초기 모델들을 언급합니다.
        1) 스코어 함수(Score Function)를 학습하는 방식
        2) 드리프트(Drift)의 초기 개념이 등장
    2) Continuous Normalizing Flows (CNF): 데이터를 연속적인 흐름(ODE/SDE)으로 변환하는 방식의 기초를 설명합니다. 여기서 드리프트 필드 $v(x, t)$의 개념이 본격적으로 등장합니다.
        1) 분포를 직접 추정하는 대신, 노이즈와 데이터를 잇는 벡터 필드(Vector Field) $v_t(x)$를 직접 학습하는 방식(Flow Matching)을 다룹니다.
        2) 우리는 이제 스코어가 아닌, 입자가 이동하는 '속도(Velocity)' 자체에 집중하기 시작 

2) 최적 운송 이론 (Optimal Transport, OT)
    1) Monge-Kantorovich 문제: 데이터를 이동시킬 때 '최소 비용'으로 이동시키는 고전적 이론을 설명합니다.
    2) Benamou-Brenier Formulation: 앞서 설명한 제곱 노름( $\|v\|^2$ )을 시간과 공간에 대해 적분하여 최소화하는 방식이 어떻게 '최적 경로'를 보장하는지 학술적 근거를 제시합니다.
        1) 기존 Flow Matching은 경로가 구불구불, 제곱 노름 규제를 쓰면 경로가 직선이 되어 효율적    

3) 경로 평활화 및 규제 기법 (Path Smoothing & Regularization)
    1) 기존 모델들이 생성 경로가 구불구불하여 계산 효율이 떨어졌던 점을 지적합니다.
    2) 이를 해결하기 위해 Velocity 기반 규제나 Optimal Transport Flow Matching 등을 도입한 최신 연구들을 소개하며, 본인의 연구와 비교합니다.


---

## 3. Drifting Models for Generation


1. 일반적인 확산 모델의 SDE 구성확산 모델은 일반적으로 다음과 같은 형태의 SDE를 통해 데이터를 노이즈로 바꾸거나, 노이즈에서 데이터를 생성합니다.

$$dx = \mathbf{f}(x, t)dt + g(t)dw$$

* 드리프트 항 ( $\mathbf{f}(x, t)dt$ ): 결정론적인 부분으로, 샘플이 시간에 따라 이동하는 평균적인 방향을 결정합니다.
* 확산 항 ( $g(t)dw$ ): 확률론적인 부분으로, 브라운 운동( $dw$ )에 의한 무작위 노이즈를 추가하여 분포를 퍼뜨리는 역할을 합니다.

### 3.1. Pushforward at Training Time

* 모델이 학습 과정에서 수학적으로 어떻게 데이터를 변형(Transformation)시키는지 그 '메커니즘'을 설명하는 핵심 파트

#### 1. Pushforward( $\sharp$ )의 개념

* 수학에서 Pushforward는 하나의 확률 분포를 함수(또는 흐름)를 통해 다른 공간으로 이동시키는 것을 의미합니다.
* 만약 우리가 학습시킨 드리프팅 필드 $v(x, t)$에 의해 정의된 흐름(Flow)을 $\phi_t$라고 한다면, 시간 $t$에서의 분포 $p_t$는 다음과 같이 표현됩니다.

$$p_t = [\phi_t]_\sharp p_0$$

* 직관적 해석: "시작점의 모래알( $p_0$ )들을 벡터 필드( $v$ )를 따라 $t$ 시간 동안 밀어냈을 때 형성된 모래 더미의 모양이 바로 $p_t$다."

#### 2. Training Time에서의 핵심 프로세스

* 학습 시에는 전체 경로를 다 계산할 수 없으므로, 보통 조건부(Conditional) 방식을 사용하여 효율적으로 'Push'를 수행합니다.
1) 데이터 쌍 샘플링 (Sampling)먼저 노이즈 데이터 $x_0 \sim p_0$와 실제 데이터 $x_1 \sim p_1$을 샘플링합니다.
2) 경로 정의 (Probability Path) $x_0$ 에서 $x_1$으로 가는 가장 단순한 경로(보통 직선)를 정의합니다. 이를 보간(Interpolation)이라고 합니다.

$$x_t = (1-t)x_0 + tx_1$$

3) 타겟 드리프트 필드 설정이 경로 $x_t$ 위에서 입자가 움직여야 할 '이상적인 속도'를 계산합니다.

$$v_t(x_t) = \frac{dx_t}{dt} = x_1 - x_0$$

이 $x_1 - x_0$가 바로 모델이 배워야 할 타겟(Ground Truth)이 됩니다.

#### 3. 제곱 노름(Squared Norm)과의 연결고리

* 모델 $v_\theta(x, t)$가 실제 타겟 $v_t$를 얼마나 잘 따라가는지 측정할 때, 우리는 두 벡터 사이의 차이의 제곱 노름을 최소화합니다.

$$\mathcal{L} = \mathbb{E}_{t, x_0, x_1} [ \| v_\theta(x_t, t) - (x_1 - x_0) \|^2 ]$$

* 왜 제곱인가? 앞서 언급했듯 미분이 용이하고, $L^2$ 거리를 최소화하는 것이 확률 분포 간의 Optimal Transport(최적 운송) 경로를 찾는 것과 수학적으로 동일하기 때문입니다.

* 학습 결과: 이 손실 함수를 최소화하면, 모델은 $p_0$에서 $p_1$으로 데이터를 보낼 때 가장 에너지를 적게 쓰는(즉, 가장 직선에 가까운) 방식으로 Pushforward하는 법을 배우게 됩니다.


### 3.2. Drifting Field for Training

#### 1. 드리프트 필드 (Drifting Field)의 정의

* 드리프트 필드는 훈련 중인 샘플 $x$가 다음 단계에서 얼마나 이동해야 하는지( $\Delta x$ )를 결정하는 함수 $V_{p,q}$입니다.
* 공식: 다음 반복(Iteration)에서의 샘플 위치는 다음과 같이 결정됩니다

$$x_{i+1}=x_i+V_{p,q_i}(x_i)$$

* 의존성: 이 필드는 데이터 분포( $p$ )와 현재 모델이 생성하고 있는 분포( $q$ )에 따라 달라집니다.

#### 2. 평형 상태와 반대칭성 (Equilibrium and Anti-symmetry)

* 모델의 궁극적인 목표는 생성 분포 $q$가 데이터 분포 $p$와 일치하게 만드는 것입니다. 이 상태를 평형(Equilibrium)이라고 하며, 이때 샘플의 이동은 멈춰야 합니다( $V=0$ ).
* 반대칭 조건: 논문은 드리프트 필드가 반대칭성 ( $V_{p,q}(x) = -V_{q,p}(x)$ )을 가져야 함을 제안합니다.
* 이 조건이 만족되면, 두 분포가 일치( $q=p$ )할 때 드리프트 필드는 자연스럽게 $0$이 되어 샘플들이 더 이상 움직이지 않는 평형 상태에 도달합니다.
* 훈련 목적함수 (Training Objective)평형 상태 조건을 바탕으로, 네트워크 $f$를 최적화하기 위한 손실 함수( $\mathcal{L}$ )를 다음과 같이 정의합니다

$$\mathcal{L}=\mathbb{E}_{\epsilon}[||f_{\theta}(\epsilon) - stopgrad(f_{\theta}(\epsilon)+V_{p,q_{\theta}}(f_{\theta}(\epsilon)))||^{2}]$$

* 작동 방식: 현재 네트워크의 예측값( $f_{\theta}(\epsilon)$ )을 '이동이 적용된 목표 상태'( $x + \Delta x$ )로 밀어붙이는 방식입니다.
* Stop-gradient: 목표 상태를 계산할 때 stopgrad를 사용하여 이전 상태를 고정함으로써, 복잡한 분포 간의 역전파 문제를 단순화합니다.
* 이 메커니즘을 통해 딥러닝 최적화 도구(optimizer)는 반복적인 훈련 과정을 거치며 생성 분포를 데이터 분포 쪽으로 자연스럽게 진화시키게 됩니다.


### 3.3. Designing the Drifting Field

* 핵심 아이디어는 생성된 샘플이 실제 데이터 쪽으로는 끌려가고(인력), 현재 생성된 다른 샘플들로부터는 밀려나게(척력) 만드는 것

#### 1. 기본 개념: 인력과 척력 (Attraction and Repulsion)

* 드리프트 필드는 두 가지 힘의 조합으로 정의

$$V_{p,q}(x) := V_{p}^{+}(x) - V_{q}^{-}(x)$$

* 인력 항 ( $V_{p}^{+}$ ): 데이터 분포 $p$에서 추출된 양성 샘플(Positive samples, $y^{+}$ )들이 $x$를 끌어당기는 힘입니다.
* 척력 항 ( $V_{q}^{-}$ ): 현재 모델이 생성한 분포 $q$에서 추출된 음성 샘플(Negative samples, $y^{-}$)들이 $x$를 밀어내는 힘입니다.
* 이 필드는 데이터 분포 $p$와 생성 분포 $q$가 일치할 때 서로 상쇄되어 $0$이 되며, 이를 통해 반대칭성(Anti-symmetry)과 평형 상태를 유지합니다.

#### 2. 커널(Kernel) 디자인

* 샘플 간의 유사도를 측정하기 위해 커널 함수 $k(x, y)$를 사용합니다. 논문에서는 지수 함수 형태의 커널을 채택했습니다

$$k(x, y) = \exp\left(-\frac{1}{\tau}||x - y||\right)$$

* 온도 매개변수 ( $\tau$ ): 거리에 따른 영향력을 조절합니다.
* 특징: 이 커널은 가까운 샘플일수록 더 강한 드리프트를 유도하여 훈련 신호를 풍부하게 제공합니다.
* 정규화: 실제 구현 시에는 Softmax 연산을 통해 가중치를 정규화하여 사용합니다.

#### 3. 최종 계산 공식

위의 요소들을 결합하면, 샘플 $x$의 최종 이동 벡터는 다음과 같이 통합된 기대치 형태로 표현됩니다:

$$V_{p,q}(x) = \frac{1}{Z_{p}Z_{q}}\mathbb{E}_{p,q}[k(x, y^{+})k(x, y^{-})(y^{+} - y^{-})]$$

* 이 공식은 양성 샘플과 음성 샘플의 차이( $y^{+} - y^{-}$ )에 커널 가중치를 곱하여 계산됩니다.
* 확률적 훈련 (Stochastic Training): 매 훈련 단계마다 미니배치(mini-batch)를 사용하여 이 기댓값을 근사치로 계산합니다.
* 음성 샘플의 재활용: 효율성을 위해 같은 배치 내에서 생성된 샘플 $x$를 음성 샘플 $y^{-}$로 재사용합니다.


#### 4. 핵심 특징 요약

* 모드 붕괴 방지: 만약 모델이 특정 지점으로 뭉치면(모드 붕괴), 데이터의 다른 부분들이 샘플을 강력하게 끌어당겨 다시 퍼지게 만듭니다.
* 유연성: 인력과 척력이 상쇄되는 평형 조건만 만족한다면 다양한 커널이나 함수 형태를 적용할 수 있습니다.
* 강건함: 정규화(Normalization) 과정을 통해 특징값의 크기나 차원에 상관없이 안정적으로 작동합니다.

### 3.4. Drifting in Feature Space

* 드리프트 손실(Drifting Loss)을 가공되지 않은 원본 데이터 공간(예: 픽셀)이 아닌, 특징 추출기(Feature Extractor)를 통해 변환된 고차원 특징 공간에서 계산하는 방법을 설명

#### 1. 특징 공간에서의 손실 함수 정의

* 고차원 데이터(이미지 등)를 효과적으로 생성하기 위해, 원본 데이터 대신 특징 추출기 $\phi$를 통과한 특징값들 사이의 드리프트를 최소화합니다.
* 손실 함수 공식

$$\mathbb{E}[||\phi(x)-stopgrad(\phi(x)+V(\phi(x)))||^{2}]$$

* 여기서 $x = f_{\theta}(\epsilon)$는 생성기의 출력물이며, $V$는 특징 공간에서 정의된 드리프트 필드입니다.

#### 2. 멀티 스케일 및 위치 활용 (Multi-scale Features)

* 하나의 특징 벡터만 사용하는 대신, 인코더의 여러 계층(Scale)과 공간적 위치(Location)에서 추출된 다양한 특징들을 결합하여 사용합니다.
* ResNet 스타일 인코더: 여러 단계의 피처 맵을 사용하여 훈련에 필요한 더 풍부한 그래디언트 정보를 제공합니다.
* 공식 확장: 각 특징 $j$에 대한 손실을 모두 합산하여 최종 손실을 구합니다.

$$\sum_{j}\mathbb{E}[||\phi_{j}(x)-stopgrad(\phi_{j}(x)+V(\phi_{j}(x)))||^{2}]$$

#### 3. 왜 특징 공간인가?

* 의미적 유사성 (Semantic Similarity): 드리프트 모델의 핵심인 커널 함수 $k(\cdot, \cdot)$가 잘 작동하려면, 의미적으로 유사한 샘플들이 특징 공간상에서 가깝게 위치해야 합니다.
* 자기주도 학습 (Self-supervised Learning): 이를 위해 MoCo, SimCLR 또는 본 논문에서 제안하는 latent-MAE와 같은 사전 훈련된 자기주도 학습 모델을 특징 추출기로 사용합니다.
* 훈련 전용: 특징 인코더는 훈련 시에만 사용되며, 추론(Inference) 시에는 전혀 필요하지 않습니다. 따라서 생성기 자체는 단일 패스로 가볍게 작동합니다.

#### 4. 기존 방식(지각 손실)과의 차이점

| 구분 | 구분지각 손실 (Perceptual Loss) | 특징 공간 드리프트 (Feature-space Drifting) |
| :--- | :--- | :--- |
| 목표 | 생성된 샘플과 특정 타겟 샘플 사이의 거리 최소화 | 생성된 분포 ($\phi_{\sharp} q$)와 데이터 분포 ($\phi_{\sharp} p$)를 일치시킴 |
| 쌍(Pairing) | 생성물 $x$와 타겟 $x_{target}$의 쌍이 필요함 (Supervised) | 샘플 간의 쌍이 필요 없으며 분포 관점에서 접근함 (Unsupervised) |

### 3.5. Classifier-Free Guidance

---

## 4. Implementation for Image Generation

---


## 5. Experiments

### 5.1. Toy Experiments

### 5.2. ImageNet Experiments

### 5.3. Experiments on Robotic Control


---

## 6. Discussion and Conclusion

---


